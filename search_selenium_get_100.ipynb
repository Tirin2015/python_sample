{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.co.jp/search?num=100&source=hp&ei=O5m4XoSCAcHj-Ab9mL_YDA&q=python+%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0\n"
     ]
    }
   ],
   "source": [
    "# Seleniumを立ち上げ検索をする\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/user/jupyternb/chromedriver_win32/chromedriver.exe')  # Optional argument, if not specified will search path.\n",
    "driver.get('https://www.google.co.jp/search?num=100');\n",
    "time.sleep(3) # Let the user actually see something!\n",
    "search_box = driver.find_element_by_name('q')\n",
    "search_box.send_keys('python スクレイピング')\n",
    "search_box.submit()\n",
    "time.sleep(3) # Let the user actually see something!\n",
    "\n",
    "url = driver.current_url\n",
    "print(url)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.co.jp/search?num=100&source=hp&ei=ahrCXrCPC4j70gSD8oKwDQ&q=python+%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0\n"
     ]
    }
   ],
   "source": [
    "# Selenium用\n",
    "import time\n",
    "from selenium import webdriver\n",
    "# スクレイピングを実施してcsvに書き出し用\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "\n",
    "# Chromedriverを立ち上げる\n",
    "driver = webdriver.Chrome('C:/Users/user/jupyternb/chromedriver_win32/chromedriver.exe')\n",
    "\n",
    "# google検索 100件表示分を指定する\n",
    "driver.get('https://www.google.co.jp/search?num=100');\n",
    "\n",
    "# 待機\n",
    "time.sleep(3)\n",
    "\n",
    "# キーの指定\n",
    "keywords = str('python スクレイピング')\n",
    "\n",
    "# 検索する\n",
    "search_box = driver.find_element_by_name('q')\n",
    "search_box.send_keys(keywords)\n",
    "search_box.submit()\n",
    "\n",
    "# 待機\n",
    "time.sleep(6)\n",
    "\n",
    "# 検索した結果のURLを取得する\n",
    "url = driver.current_url\n",
    "\n",
    "# Chromedriverを止める\n",
    "driver.quit()\n",
    "\n",
    "print(url)\n",
    "\n",
    "# ヘッダーの指定\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "}\n",
    "\n",
    "# 検索結果のURLを指定する\n",
    "get_url = requests.get(url, headers=headers)\n",
    "get_url.raise_for_status()\n",
    "\n",
    "# 取得したURLのソースをスクレイピングする\n",
    "soup = BeautifulSoup(get_url.text, 'lxml')\n",
    "\n",
    "# 検索結果のタイトルとリンクを取得する\n",
    "link_title = soup.select('.r > a')\n",
    "\n",
    "# 検索結果の説明部分を取得する\n",
    "link_disc = soup.select('.s > div > .st')\n",
    "\n",
    "# 検索結果を数える\n",
    "if(len(link_disc) <= len(link_title)):\n",
    "    leng = len(link_disc)\n",
    "else:\n",
    "    leng = len(link_title)\n",
    "    \n",
    "# csvファイルを書き込み用にオープンして整形して書き出す\n",
    "with open('output/' + '['+ keywords + ']_g_output_2.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(['タイトル', '説明', 'URL'])\n",
    "    for num in range(leng):\n",
    "        # リンクのみを取得し、余分な部分を削除する\n",
    "        url_text = link_title[num].get('href').replace('/url?q=','')\n",
    "        \n",
    "        # タイトルのテキスト部分のみを取得する\n",
    "        title_text = link_title[num].get_text()\n",
    "        \n",
    "        # 説明のテキスト部分のみを取得／余分な改行コードを削除する\n",
    "        text_1 = link_disc[num].get_text()\n",
    "        text_2 = text_1.replace('\\n', '')\n",
    "        disc_text = text_2.replace('\\r', '')\n",
    "        csvwriter.writerow([title_text, disc_text, url_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>タイトル</th>\n",
       "      <th>説明</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>【初心者向け】PythonでWebスクレイピングをしてみよう!手順まとめ ...www.se...</td>\n",
       "      <td>2018/05/07 - PythonでWebスクレイピングをする方法が知りたい！ 今割と界...</td>\n",
       "      <td>https://www.sejuku.net/blog/51241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>［Python入門］Beautiful Soup 4によるスクレイピングの基礎 (1/2 ....</td>\n",
       "      <td>2019/10/18 - スクレイピング（scraping）とは、Webサイトに表示されたH...</td>\n",
       "      <td>https://www.atmarkit.co.jp/ait/articles/1910/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable....</td>\n",
       "      <td>2019/02/26 - 追記 2020年3月. DAINOTE編集部で、Pythonによる...</td>\n",
       "      <td>https://dividable.net/python/python-scraping/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>図解！PythonでWEB スクレイピングを極めろ！(サンプルコード ...ai-inter...</td>\n",
       "      <td>2020/05/05 - Pythonでのスクレイピングのやり方について初心者向けに解説した...</td>\n",
       "      <td>https://ai-inter1.com/python-webscraping/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PythonによるWebスクレイピングの方法 | TechAcademyマガジンtechac...</td>\n",
       "      <td>Pythonにおけるスクレイピングのためフレームワークといえば、Scrapyです。 Scra...</td>\n",
       "      <td>https://techacademy.jp/magazine/20930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                タイトル  \\\n",
       "0  【初心者向け】PythonでWebスクレイピングをしてみよう!手順まとめ ...www.se...   \n",
       "1  ［Python入門］Beautiful Soup 4によるスクレイピングの基礎 (1/2 ....   \n",
       "2  【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable....   \n",
       "3  図解！PythonでWEB スクレイピングを極めろ！(サンプルコード ...ai-inter...   \n",
       "4  PythonによるWebスクレイピングの方法 | TechAcademyマガジンtechac...   \n",
       "\n",
       "                                                  説明  \\\n",
       "0  2018/05/07 - PythonでWebスクレイピングをする方法が知りたい！ 今割と界...   \n",
       "1  2019/10/18 - スクレイピング（scraping）とは、Webサイトに表示されたH...   \n",
       "2  2019/02/26 - 追記 2020年3月. DAINOTE編集部で、Pythonによる...   \n",
       "3  2020/05/05 - Pythonでのスクレイピングのやり方について初心者向けに解説した...   \n",
       "4  Pythonにおけるスクレイピングのためフレームワークといえば、Scrapyです。 Scra...   \n",
       "\n",
       "                                                 URL  \n",
       "0                  https://www.sejuku.net/blog/51241  \n",
       "1  https://www.atmarkit.co.jp/ait/articles/1910/1...  \n",
       "2      https://dividable.net/python/python-scraping/  \n",
       "3          https://ai-inter1.com/python-webscraping/  \n",
       "4              https://techacademy.jp/magazine/20930  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('output/' + '['+ keywords + ']_g_output_2.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
