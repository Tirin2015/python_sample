{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.co.jp/search?num=100&source=hp&ei=O5m4XoSCAcHj-Ab9mL_YDA&q=python+%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/user/jupyternb/chromedriver_win32/chromedriver.exe')  # Optional argument, if not specified will search path.\n",
    "driver.get('https://www.google.co.jp/search?num=100');\n",
    "time.sleep(3) # Let the user actually see something!\n",
    "search_box = driver.find_element_by_name('q')\n",
    "search_box.send_keys('python スクレイピング')\n",
    "search_box.submit()\n",
    "time.sleep(3) # Let the user actually see something!\n",
    "\n",
    "url = driver.current_url\n",
    "print(url)\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.co.jp/search?source=hp&ei=TSC5XsTVJKOh-Qan-ZC4DQ&q=python+%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0+%E8%87%AA%E5%8B%95%E5%8C%96\n",
      "{'TITLE': ['pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › blog › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › blog › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scraping-software-to-...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › blog › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › blog › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scraping-software-to-...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › blog › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › blog › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scraping-software-to-...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog', 'pythonで自動入力、スクレイピングをしてみる - Qiitaqiita.com › Python', '【完全版】PythonとSeleniumでブラウザを自動操作(クローリング ...tanuhack.com › Python › Selenium', '【Python入門】スクレイピングを使って自動的にWebページから ...blog.codecamp.jp › 子ども向け', 'Pythonでブラウザを自動操作する方法 | ガンマソフト株式会社gammasoft.jp › python-browser-automation-by-selenium', 'PythonとSeleniumを使ったブラウザ自動操作 – 名古屋のWeb ...www.inet-solutions.jp › 技術関連情報', '【保存版】Pythonでスクレイピングする方法を初心者向けに徹底 ...dividable.net › python › python-scraping', 'Pythonで毎日圧倒的に効率化している業務自動化術5選 【非 ...dividable.net › python › python-automation', 'スクレイピングツール30選｜初心者でもWebデータを抽出できる ...www.octoparse.jp › top-30-free-web-scraping-software', '業界初！Webデータを自動収集できるWebスクレイピング ...www.octoparse.jp › blog › a-revolutionary-web-scrapin...', 'Pythonの自動化でどんなことができるのかその全てを紹介する | 侍 ...www.sejuku.net › blog'], 'DESCRIPTION': ['2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...', '2019/04/15 - ... クローラーで取ってきたデータを解析するのであればpythonの方が便利じゃね？っていう助言を頂いたので、pythonを使ってみました。 今回やったのは、seleniumからGoogle Choromeを呼び出して自動ログインし、スクレイピングする作業。', '2020/03/27 - 【完全版】PythonとSeleniumでブラウザを自動操作(クローリング／スクレイピング)するチートシート ... というサードパーティ製のモジュールを用いれば、Google ChromeやFirefoxなどのブラウザで行っている操作を自動化することができます。', '2020/01/29 - 今回は Python ライブラリの Selenium を使って、 225このファイルを自動的にダウンロードしてみました。 【今回スクレイピングで使用するブラウザ】 ・ FireFox ・ Google Chrome. \"CodeCampus\"はオンラインプログラミングスクール No.', '2019/08/14 - PythonとSelenium WebDriverを使って Chromeを自動操作する方法 をわかりやすく説明します。Pythonで出来ることは実に多様ですが、なかでもスクレイピングや今回のブラウザ操作はよく用いられる使い方の1つです。 今回は「東京駅＋\\xa0...', 'Webスクレイピングの実例 に移動 - スクレイピングをしようとするとBeautifulSoup等のライブラリを使う例をよく見ますが、できるだけシンプルに動作できるように導入するのはPythonとSelenium、WebDriverだけにとどめ、必要最小限のものだけで動作させ\\xa0...', 'Webサイトの関連キーワードを自動取得し、リバースエンジニアリング に移動 - DAINOTE編集部で、Pythonによるスクレイピングの方法について、無料チュートリアルを公開しました。未経験の方でもブログからデータを自動抽出できるチュートリアルなので、\\xa0...', '2018/10/26 - Pythonで毎日の業務が自動化できたら、非常に便利ですよねそこで、今回は僕がPythonで毎日圧倒的に効率化している ... ということがわかり、このキーワードを使って 【Python】スクレイピング→データ収集→整形→分析までの流れを初心者\\xa0...', '幸いなことに、今では、コーディングをしなくてもWebデータを自動抽出できるスクレイピングソフトは様々です。 これらのソフト ... 使う理由：Beautiful Soupは、HTMLやXMLファイルをスクレイピングするために設計されたオープンソースのPythonライブラリです。', 'もちろん、Pythonを書いて、製品名、レビュー、価格などのような望ましい情報を抽出するためにスクレイピングロボットを作ることもできます。しかし、プログラミング技術を持っていない販売者にとって、Webから有用なデータを取得するためのコーディング方法を\\xa0...', 'スクレイピング に移動 - 1 Pythonで自動化とは具体的にどういうこと？ 2 自動化の事例. 2.1 スクレイピング; 2.2 Webの自動化; 2.3 APIを利用して自動化\\xa0...'], 'URL_LINK': ['https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240', 'https://qiita.com/fujigaki/items/db8a97c4a679ba1e3208', 'https://tanuhack.com/selenium/', 'https://blog.codecamp.jp/programming-python-scraping', 'https://gammasoft.jp/blog/python-browser-automation-by-selenium/', 'https://www.inet-solutions.jp/technology/python-selenium/', 'https://dividable.net/python/python-scraping/', 'https://dividable.net/python/python-automation/', 'https://www.octoparse.jp/blog/top-30-free-web-scraping-software/', 'https://www.octoparse.jp/blog/a-revolutionary-web-scraping-software-to-boost-your-business-easier/', 'https://www.sejuku.net/blog/75240']}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# Chromeを立ち上げる\n",
    "# ローカル環境での「chromedriver.exe」のパスを指定する\n",
    "chrome = webdriver.Chrome(\"C:/Users/user/jupyternb/chromedriver_win32/chromedriver.exe\")\n",
    "chrome.get('https://www.google.co.jp/')\n",
    "\n",
    "# 検索キーワードの指定・・・ \"python スクレイピング\" のように２語以上の場合は、半角スペースを追加する\n",
    "keyword = \"python スクレイピング 自動化\"\n",
    "# 取得ページの指定数\n",
    "per = \"10\" \n",
    "\n",
    "# 検索実行\n",
    "search_box = chrome.find_element_by_name('q')\n",
    "search_words = keyword\n",
    "search_box.send_keys(search_words)\n",
    "search_box.submit()\n",
    "\n",
    "# 3秒間スリープ\n",
    "time.sleep(3)\n",
    "\n",
    "# 検索を実行したURLを取得する\n",
    "cur_url = chrome.current_url\n",
    "print(cur_url)\n",
    "\n",
    "# データの格納の準備する\n",
    "result = {}\n",
    "title_text_value = []\n",
    "disc_text_value = []\n",
    "url_text_value = []\n",
    "\n",
    "# 関数\n",
    "def response_get():\n",
    "    # ヘッダー情報を指定する\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    }\n",
    "\n",
    "    r = requests.get(cur_url, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    \n",
    "    # 検索結果のタイトルとリンクを取得\n",
    "    link_title = soup.select('.r > a')\n",
    "\n",
    "    # 検索結果の説明部分を取得\n",
    "    link_disc = soup.select('.s > div > .st')\n",
    "    \n",
    "    if(len(link_disc) <= len(link_title)):\n",
    "        leng = len(link_disc)\n",
    "        for i in range(leng):\n",
    "            try:\n",
    "                # タイトルのテキスト部分のみを取得\n",
    "                title_text = link_title[i].get_text()\n",
    "                title_text_value.append(title_text)\n",
    "                result[\"TITLE\"] = title_text_value\n",
    "\n",
    "                # 説明のテキスト部分のみを取得／余分な改行コードを削除する\n",
    "                t01 = link_disc[i].get_text()\n",
    "                t02 = t01.replace('\\n', '')\n",
    "                disc_text = t02.replace('\\r', '')\n",
    "                disc_text_value.append(disc_text)\n",
    "                result[\"DESCRIPTION\"] = disc_text_value \n",
    "\n",
    "                # リンクのみを取得し、余分な部分を削除する\n",
    "                url_text = link_title[i].get('href').replace('/url?q=','')\n",
    "                url_text_value.append(url_text)\n",
    "                result[\"URL_LINK\"] = url_text_value                           \n",
    "               \n",
    "                # 次ページ取得・遷移\n",
    "                next = chrome.find_element_by_css_selector(\"#foot table td.cur + td a\")\n",
    "                next.click()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # 5秒間スリープ\n",
    "            time.sleep(5)  \n",
    "\n",
    "    else:\n",
    "        leng = len(link_title)\n",
    "        print(\"取得おわり\")\n",
    "\n",
    "\n",
    "# 検索結果を取得する\n",
    "for i in range(int(per)):\n",
    "    response_get()\n",
    "\n",
    "# chromeを閉じる\n",
    "chrome.close()\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "# 検索結果をCSVに出力する\n",
    "r = zip(*result.values())\n",
    "fieldnames = ['TITLE', 'DESCRIPTION', 'URL_LINK']\n",
    "\n",
    "with open('./output/[' + keyword + ']search_selenium_google_it.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    dict_writer = csv.writer(f)\n",
    "    dict_writer.writerow(fieldnames)\n",
    "    for d in r:\n",
    "        dict_writer.writerow(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
